# -*- coding: utf-8 -*-
"""PHYS798Z_PS2_PartB.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KqdUVZjsFvOk6NRY2O-KSHhqYw49Z0zu

# **PART B: GROUP-WORK PORTION**

**Group members: Daniel Callow, Joyneel Misra, Junaid Merchant, Phillip Alvarez, Gloria Kim**

Before we begin to study and manipulate different network models and characteristics of network components, we start by downloading the necessary python packages/functions. 


*   Network x: Helps create, manipulate, and examine complex networks. 
*   Matplotlib: Helps with data visualization, which we will use to plot histograms showing degree distributions later on. 
*   Counter:  Makes a container that tracks how many times equivalent values are added, which will be used for making histograms of degree distributions later. 
*   Random: A random number generator
*   Numpy: A python library used for working with arrays
"""

#Import all libraries and dependencies
import networkx as nx
from networkx.algorithms.centrality import edge_betweenness_centrality
from networkx.algorithms.bipartite.generators import configuration_model as bipartite_configuration_model
from networkx.algorithms.bipartite.projection import projected_graph as project_graph
import matplotlib as mplot
# ADDED TO BE MORE CONSISTENT WITH MOST OTHER PYTHON CODE:
import matplotlib.pyplot as plt
# add counter for histograms 
from collections import Counter
import random
import numpy as np
import statistics

"""### **QUESTION 1:** 
### Exploring clustering in Bipartite networks with the configuration model.

**(a)** 
**Plot the probability distribution of degrees of individuals in your projected networks. In other
words, take 200x10 values for node degrees and plot their distribution in a single normalized
histogram. Does this plot make sense in light of your answer for question A5? Explain.**
"""

# We start by generating the bipartite configuration network, with 2 types of 
# nodes, Type A (200 nodes, all with degree 2) and Type B (50 nodes, all with 
# degree 8). 

# Setting up Type A nodes:

# Variable a serves as node labels, as well as a counter for the loop below that gives 
# each Type A node a degree of 2. 
a = list(range(0,200))

# We then set up an empty list of degrees for a
A=[]

# We then loop through and give each node a degree of 2 using the append function. 
for n in a:
  A.append(2)
# We print the degrees of Type A nodes to screen as a sanity check (should be all 2s).
print(A)

#Setting up Type B nodes: 

# b will serve as node labels, as well as the counter for the loop below that gives
# each Type B node a degreee of 8. 
b = list(range(0,50))

# We then set up an empty list of degrees for b. 
B=[]

# We then loop through and give each node a degree of 8 using the append function. 
for n in b:
  B.append(8)
# We print the degrees of Type B nodes to screen as a sanity check (should be all 8s).
print(B)

# Using networkX's bipartite.generator.configuration model function, we now 
# create random bipartite graphs, using the Type A nodes and Type B node
# degree lists (list A and list B). 

# We set up an empty list D, where later we will append each bipartite network 
# (we will generate 10 random graphs) to this list by looping through 10 seeds
# for analysis later.  
D=[]

# For each of the 10 graphs' projections, we set up an empty list P which will 
# be used to store information about each of the projected networks. 
P=[]

# Finally, we loop through this following code 10 times to create 10 bipartite
# graphs that meet the degree specifications we made earlier. Information about
# these graphs are stored in list D, and information about the projections of 
# these graphs are stored in list P. 
for n in range(0,10):
  # Creating bipartite graph using specified parameters
  graph=nx.algorithms.bipartite.generators.configuration_model(A,B, seed=n)
  # Append graph to D
  D.append(graph)
  # Turning graph into a non-multi graph format which is necessary so we can 
  # perform calculations and do plotting later. 
  g2=nx.Graph(graph)
  # Appending the projection of the individuals to P using networkx projection function.
  P.append(nx.algorithms.bipartite.projected_graph(g2,a))

# An example of what the plotted bipartite graph looks like, with 200 Type A nodes
# on the left, and 50 Type B nodes on the right. 
nx.draw_networkx(D[0], pos = nx.drawing.layout.bipartite_layout(D[0], a), width = .04, with_labels=False, node_size=2)

"""Plotting the degree distribution of the 200x10 Type A nodes in a single histogram: """

# First, we will set up an empty list called "Deg" to add information about 
# each node's degree using the append function. The list form is ideal to store
# this information since a list of values is the ideal input format when making
# a histrogram. 
Deg=[]

# Here, we loop through all 10 iterations of making the bipartite network projections.
for i in range(0,10):
# We loop through all the nodes, and add their degree to the degree list.
  for node in a:
    # add degree to list
    Deg.append(P[i].degree(node))
  
# Now we'll create a normalized histogram from scratch using barplot instead of:
#counts, bins, patches = plt.hist(Deg, bins=10).

# We use the counter function to count the number of nodes for each degree value. 
degree_counts = Counter(Deg)

# We then calculate the minimum and maximum degrees that exist in our data. 
min_degree, max_degree = min(degree_counts.keys()), max(degree_counts.keys())

# We use the min and max degree values to set up the x-axis scale for our 
# histogram. 
plot_x = list(range(min_degree, max_degree + 1))

# We now count how many nodes of each degree we have, and set it to plot on the 
# y axis.
plot_y = [degree_counts.get(x, 0) for x in plot_x]

# We then normalize the values for y axis by 2000 nodes so we're actually 
# plotting the proportion of nodes with each degree value.
normY = [x / 2000 for x in plot_y]
plt.bar(plot_x, normY)

# Lastly, we label the histogram's axis and give it a nice title. 
plt.title('Histogram of degree distribution for projected graphs')
plt.xlabel('Degree')
plt.ylabel('Probability of nodes with degree value')

"""**Does this plot make sense in light of your answer for question A5? Explain.**

In problem 5, we considered a bipartite configuration model with nodes type A and type B. We generated expressions for the expected number of nodes reachable in "n" steps if I started at a node that was Type A. 

In our histogram, we see that the degree with the highest probability seems to be 14. 14 = `<ka>*(<kb^2> - <kb> / <kb>)` (aka C^2_A) so this makes sense.

**(b)** 
**Calculate and plot the probability distribution of the local clustering coefficient of individuals in
your projected networks. In other words, take 200x10 values for the local clustering coefficient
and plot their distribution in a single normalized histogram.**
"""

# Using a similar approach as above, we will plot the probability distribution 
# of local clustering coefficients of the individuals in our projected graphs. 

# We first set up an empty list called "CC" to add each node's clustering 
# coefficient to the list using the append function.
CC=[]

# We then loop through all 10 iterations of the bipartite network projections
for i in range(0,10):
# and loop through all the nodes, adding their clustering coefficient to the list. 
  for node in a:
    # We use the network x's clustering function to calculate the clustering coefficients. 
    CC.append(nx.algorithms.cluster.clustering(P[i],node))
  
# Now we create a normalized histogram using matplotlib's histogram function:
counts, bins, patches = plt.hist(CC, bins=23,density=1)

# Finally, we add axis labels and a nice title.
plt.title('Histogram of clustering coefficient probability distribution for projected graphs')
plt.xlabel('Clustering coefficient (cc)')
plt.ylabel('Percent of nodes with cc value')

"""**(c)** 
**Consider a G(N,p) network model with the same average degree and number of nodes as in
your projected network realizations. What would be the average local clustering coefficient for
this network (from theory)? Does it differ significantly from what you observed in (b)? Why or why not?**
"""

avg_degree = statistics.mean(Deg)
avg_local_clustering_coefficient = statistics.mean(CC)
print(f"Average local clustering coefficient for the projected graph over individuals is {avg_local_clustering_coefficient}")
print(f"p for the equivalent G(N,p) model is = <k>/(N-1) = {avg_degree}/{200-1} = {avg_degree/199}")

"""The expression for a local-clustering coefficient for a node $i$ in the network is:
$$C_i = \frac{2 \langle L_i\rangle}{k_i(k_i-1)}$$
Where $k_i$ is the degree of node $i$ and $L_i$ is the number of links between $k_i$ neighbors of node $i$.

After plugging in the $G(N,p)$ network model, we have:
$$\langle L_i \rangle= p \times \text{#\{of neighbor pairs on average\}} = p \frac{k_i(k_i-1)}{2}$$

So $C_i$ can be rewritten as:
$$C_i = \frac{2p \frac{k_i(k_i-1)}{2}}{k_i(k_i-1)} = p$$

The average local clustering coefficient of the $G(N,p)$ network will be:
$$C = \frac{1}{N} \sum\limits_{i} C_i = \frac{Np}{N} = p$$

**Average local clustering coefficients for** 
1. projected networks over individuals = $0.491$
2. equivalent G(N, p) network = $0.068$
So both values differ significantly from each other. 

It is expected because of the following reasons:
- The way the projected networks are constructed is, all individuals associated with a group form a fully connected graph (clique!). So the network is expected to have **high** average local clustering coefficient due to presence of cliques in it.
-  Each of the $200$ individual can belong to $2$ groups at maximum. Each group can contain atmost $8$ individuals each. So no individual would have degree greater than $2\times(8-1) = 14 << 200$ in the projected network! Therefore due to the low average degree $\langle k\rangle = 13.6$ in the projected networks, average local clustering coefficient of the G(N,p) model = $p$ = $\frac{\langle k\rangle}{N}$ is also low!

###**QUESTION 2:** 
###Edge betweenness in Small-World Networks.

**(a)**
**A table in which different rows give results for the different rewiring probabilities. Your table
should have the following five columns: rewiring probability, number of shortcut edges; average
betweenness of all edges, average betweenness of short-cut edges; average betweenness of
non-short-cut edges.**

**Step 1:** 
To examine edge betweenness in an example small-world network, we first need to build the Watts-Strogatz small-world network. We start with a 1D lattice ring composed of 500 nodes, where each node connects to its 4 nearest neighbors, 2 connections per side. 

To put this question into context, edge betweenness is the number of shortest paths that pass through a specific edge in a network. An edge with high betweenness can be said to play a "bridge" or "connector" like role for two parts of a network (e.g., think of a network with 2 communities linked by a single edge between them).

**Step 2:** 
The next step is to generate the same 1D lattice ring with 500 nodes, **BUT** have the connections be made with different rewiring probabilities. Below, we repeatedly generate the same general ring graph BUT set rewiring probabilities as: 0, 0.01, 0.05, 0.1, and 1.
"""

def generate_small_world_network(N, nn, p):
  '''
  generates small world network (G) with

  N: number of nodes in our 1D lattice ring
  nn: degree of each node
  p: rewiring probability

  We use Watts-Strogatz model to generate G
  '''

  '''
  STEP1: Construct a regular ring lattice of N nodes,
         each connected to its k neighbors, k/2 on each side
  '''
  # First, we want to set the shape of our network to be a ring.
  G = nx.cycle_graph(N)

  # From each node, we are now adding a connection to its k nearest neighbors,
  # and looping through each node in the network.
  for node in G.nodes:

    # connect every node to only ith neighbor to the right as well as left
    # this way every node will be connected to its ith
    # nearest-neighbors in either direction
    for i in range(1, nn // 2 + 1):
      
      left_neighbor  = (node + i) % N
      right_neighbor = (node + i) % N
      G.add_edge(node, left_neighbor)
      G.add_edge(node, right_neighbor)

  '''
  STEP2: For every node, rewire every edge with right neighbors 
         to any other node with probability p.

         What does it mean to rewire an edge? It means that for each edge (u,v),
         replace (u,v) with (u,w) with probability p, where w is NOT a neighbor
         of node u. 

         Avoid creation of self loops or multiple edges during 
         this process.
  '''

  # we take the edge list of our graph "G" and iterate over it
  for u, v in list(G.edges):
    # rewire the edge (u, v) with probability p
    if random.random() < p:
        
        # choose possible new nodes for rewiring
        not_neighbors = set(G.nodes) - set(G.neighbors(u))
        
        # choose a w and 
        # rewire (u, w) in place of (u, v)
        w = random.choice(list(not_neighbors))

        G.remove_edge(u, v)
        G.add_edge(u, w)
  
  return G

# Now we start setting up to generate small world graphs with different
# rewiring probabilities. 

# We first set the number of nodes we want in our 1D lattice ring, 
# which in this case is 500 nodes. 
N = 500

# The question specifies that each node in the ring should connect 
# to its 4 nearest neighbors. We specify this below, with "nn" 
# representing Nearest Neighbors. 
nn=4

# We generate small world graphs with different rewiring probabilities
# and store them in a list.

small_world_graphs = []
rewiring_probabilities = [0, 0.01, 0.05, 0.1, 1]

for i, p in enumerate(rewiring_probabilities):

  G = generate_small_world_network(N, nn, p)
  small_world_graphs.append(G)

  plt.subplot(2, 3, i+1, title=f"p={p}")
  nx.draw_circular(G, with_labels=False, node_size=.5, width = .1)
  
plt.show()

"""**Step 3**: To calculate edge betweenness of ALL edges, SHORT-CUT edges, and NON-SHORT-CUT edges:"""

# We use the function below to find all of the shortcut edges in the graph.  
def get_shortcut_edges(G, N, nn):
  '''
  function to find shortcut edges in the graph
  '''
  
  # We then create a lists of shortcut and non-shortcut edge indices.
  SE_indices = []
  NSE_indices = []
  
  # Looping through EACH edge in the edge list in the graph, we
  # determine if edges are shortcuts or not. 
  for edge_index, (u, v) in enumerate(list(G.edges)):
    
    # We can say that (u, v) is a shortcut if distance between u and v
    # is greater than nn. Here we use "append" to add an edge to their 
    #respective existing list when the edge qualities as a shortcut or not. 
    if min(abs(u - v), N - abs(u - v)) > nn/2:
      SE_indices.append(edge_index)
    else:
      NSE_indices.append(edge_index)
      
  return SE_indices, NSE_indices

# Below, we set up several empty lists for the numbers we will need to report
# edge betweenness. 

# number of shortcut edges empty list
NSE = []
# mean overall betweenness 
MOB = []
# SD overall betweenness
SOB = []
# mean shortcut betweenness 
MSB = []
# SD shortcut betweenness
SSB = []
# mean nonshortcut betweenness 
MNB = []
# SD nonshortcut betweenness
SNB = []

# Now, we create the shortcut and non-shortcut edge lists and calculate 
# betweenness values for EACH of the graphs we made in step 2. 
for G in small_world_graphs:

  # making lists of shortcut and non-shortcut edge indices:
  SE_indices, NSE_indices = get_shortcut_edges(G, N, nn)

  # getting number of shortcut edges:
  NSE.append(len(SE_indices))

  # calculating the betweeness values of all edges into a list:
  Betweens=np.array(list(edge_betweenness_centrality(G).values()))

  # adding the Mean and SD betweenness to the lists
  
  # 1) all edges
  MOB.append(Betweens.mean())
  SOB.append(Betweens.std())
  
  # 2) shortcut edges
  MSB.append(Betweens[SE_indices].mean())
  SSB.append(Betweens[SE_indices].std())
  
  # 3) non-shortcut edges
  MNB.append(Betweens[NSE_indices].mean())
  SNB.append(Betweens[NSE_indices].std())

# Finally, we create a table to fill in the betweenness values for the 
# different rewiring probabilities. 

# We start by importing plotly, which will be used for table functions.
import plotly.graph_objects as go

# Here are the values that we need to plot for each of the cells in the table.
num_shortcut_edges=NSE
avg_btweeness_all_edges=[]
avg_btweeness_shortcut_edges=[]
avg_btweeness_non_shortcut_edges=[]

# We then loop through the lists created in previous cell to populate values 
# of the table.
for c in range(len(rewiring_probabilities)):
  # concatenate strings to get in format desired, and reduce the decimal places to 6
  avg_btweeness_all_edges.append(str('%.6f' % MOB[c]) +' ± (' + str('%.6f' % SOB[c]) + ')')
  avg_btweeness_shortcut_edges.append(str('%.6f' % MSB[c]) +' ± (' + str('%.6f' % SSB[c]) + ')')
  avg_btweeness_non_shortcut_edges.append(str('%.6f' % MNB[c]) +' ± (' + str('%.6f' % SNB[c]) + ')')

# Lastly, we plot all the values in a table, where we found the number of
# shortcut edges, average betweenness of all edges, and average betweenness
# of non-shortcut edges for graphs of each rewiring probability. 
figure=go.Figure(data=go.Table(header=dict(values=['Rewiring Probability','Number of shortcut edges', 'Average (SD) betweenness of all edges', 'Average (SD) betweenness of short-cut edges', 'Average (SD) betweenness of non-short-cut edges']), cells=dict(values=[['p=0','p=.01','p=.05','p=.1','p=1'],NSE,avg_btweeness_all_edges,avg_btweeness_shortcut_edges,avg_btweeness_non_shortcut_edges])))

# Display the table. 
figure.show()

"""###**QUESTION 3:** 
###Contributions of group members.

All members discussed approaches, potential troubleshooting, and solutions for parts A/B over 2 virtual meetings where everyone attended. Daniel, Junaid, and Joyneel wrote the preliminary code for Part B, while Gloria, Phillip, and Joyneel checked code, made edits, and commented/formatted the code. Gloria attempted to use igraph in R as an alternative way to solve Part B. All group members reviewed the solutions before submission and discussed answers. We confirm that each member has a working and tested copy of this group's code in our own files.
"""